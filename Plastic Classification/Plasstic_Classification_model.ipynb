{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21758,"status":"ok","timestamp":1734066018946,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"L2VlIQKGKd2k","outputId":"7e00c2ee-2f01-49b0-d03d-2f1093db7b97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14721,"status":"ok","timestamp":1734066033663,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"FtgYrw_DKlrT","outputId":"ffb6639e-43dd-4287-92c6-d2864825c1ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU: []\n"]}],"source":["import tensorflow as tf\n","print(\"Using GPU:\", tf.config.list_physical_devices('GPU'))"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1734066033663,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"Y2pMZNqjKoWe"},"outputs":[],"source":["# Importing necessary libraries from TensorFlow and others\n","from tensorflow.keras.applications import MobileNetV2  # Pretrained MobileNetV2 model\n","from tensorflow.keras.models import Sequential         # Sequential model structure\n","from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D  # Various layers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator          # For image preprocessing\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau      # Callbacks for training\n","import os"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1734066033663,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"SV9oTn2wKtxp"},"outputs":[],"source":["# Setting up the training data path\n","train_path = '/content/drive/Shareddrives/capstone/capstone_ml/datasets2/train'\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1734066033663,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"gAAKswh7bDAQ"},"outputs":[],"source":["# Image dimensions and batch size configuration\n","img_width, img_height = 224, 224\n","batch_size = 32\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2581,"status":"ok","timestamp":1734066036241,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"VV_mD4-5KzQO","outputId":"1676daae-990a-4d90-acac-8311fc11fbe8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 672 images belonging to 6 classes.\n","Found 168 images belonging to 6 classes.\n"]}],"source":["# Data augmentation for training data\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,                   # Normalize pixel values to [0, 1]\n","    validation_split=0.2,             # 20% of data for validation\n","    rotation_range=40,                # Random rotations\n","    width_shift_range=0.2,            # Horizontal shifts\n","    height_shift_range=0.2,           # Vertical shifts\n","    shear_range=0.2,                  # Shear transformations\n","    zoom_range=0.2,                   # Zoom-in and zoom-out\n","    vertical_flip=True,               # Flip images vertically\n","    horizontal_flip=True,             # Flip images horizontally\n","    brightness_range=[0.8, 1.2],      # Adjust brightness\n","    fill_mode='nearest',              # Fill missing pixels after transformations\n",")\n","\n","# Preprocessing for validation data\n","val_datagen = ImageDataGenerator(\n","    rescale=1./255,                   # Normalize pixel values to [0, 1]\n","    validation_split=0.2              # 20% of data for validation\n",")\n","\n","# Generating batches of augmented training data\n","train_generator = train_datagen.flow_from_directory(\n","    train_path,\n","    target_size=(img_width, img_height),  # Resize images to target dimensions\n","    batch_size=batch_size,\n","    class_mode='categorical',             # Multi-class classification\n","    subset='training'                     # Use training subset\n",")\n","\n","# Generating batches of validation data\n","validation_generator = val_datagen.flow_from_directory(\n","    train_path,\n","    target_size=(img_width, img_height),  # Resize images to target dimensions\n","    batch_size=batch_size,\n","    class_mode='categorical',             # Multi-class classification\n","    subset='validation'                   # Use validation subset\n",")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5247,"status":"ok","timestamp":1734066042636,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"yw2rq85lLFJs","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cdbfc3ca-5b44-4d6d-b5e2-5440e8bb7ab8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}],"source":["# Load the MobileNetV2 base model without the top layer\n","base_model = MobileNetV2(input_shape=(img_width, img_height, 3), include_top=False, weights='imagenet')\n","base_model.trainable = False  # Freeze the base model weights\n"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":295,"status":"ok","timestamp":1734066047115,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"LgRMskJaLIH-"},"outputs":[],"source":["# Building the full model using Sequential API\n","model = Sequential([\n","    base_model,                          # Add the base model\n","    GlobalAveragePooling2D(),            # Reduce feature dimensions\n","    Dense(128, activation='relu'),       # Fully connected layer with ReLU activation\n","    Dropout(0.5),                        # Dropout for regularization\n","    Dense(6, activation='softmax')       # Output layer for 6 classes\n","])\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":322},"executionInfo":{"elapsed":287,"status":"ok","timestamp":1734066052687,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"},"user_tz":-420},"id":"784MlhZLLJUV","outputId":"a088b5e1-0c80-4dee-8fc3-94cfcf43131b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n","│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m163,968\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)                   │             \u001b[38;5;34m774\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ mobilenetv2_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">774</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,422,726\u001b[0m (9.24 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,422,726</span> (9.24 MB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,742\u001b[0m (643.52 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,742</span> (643.52 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n","</pre>\n"]},"metadata":{}}],"source":["# Compile the model with Adam optimizer, categorical crossentropy loss, and accuracy metric\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()  # Print the model summary\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"FWCcIyx8LMz-","executionInfo":{"status":"ok","timestamp":1734066057785,"user_tz":-420,"elapsed":317,"user":{"displayName":"Ashri Aulia Azzahra M672B4KX0694","userId":"07956476678387516129"}}},"outputs":[],"source":["# Callbacks to monitor and adjust training\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)  # Stop early to avoid overfitting\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)     # Reduce learning rate when stuck\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"OTPr_-K0LO9J","outputId":"b7725903-e24d-4bdd-c1ff-c594cfd934b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 8s/step - accuracy: 0.3027 - loss: 1.8262 - val_accuracy: 0.6190 - val_loss: 1.1029 - learning_rate: 0.0010\n","Epoch 2/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.6388 - loss: 1.0429 - val_accuracy: 0.7560 - val_loss: 0.8970 - learning_rate: 0.0010\n","Epoch 3/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.7345 - loss: 0.7342 - val_accuracy: 0.7381 - val_loss: 0.8050 - learning_rate: 0.0010\n","Epoch 4/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7590 - loss: 0.6821 - val_accuracy: 0.7381 - val_loss: 0.8180 - learning_rate: 0.0010\n","Epoch 5/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 2s/step - accuracy: 0.7652 - loss: 0.6153 - val_accuracy: 0.7917 - val_loss: 0.7317 - learning_rate: 0.0010\n","Epoch 6/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.8526 - loss: 0.4347 - val_accuracy: 0.7679 - val_loss: 0.7104 - learning_rate: 0.0010\n","Epoch 7/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.8705 - loss: 0.4225 - val_accuracy: 0.7500 - val_loss: 0.7397 - learning_rate: 0.0010\n","Epoch 8/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.8632 - loss: 0.3892 - val_accuracy: 0.7976 - val_loss: 0.7205 - learning_rate: 0.0010\n","Epoch 9/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 2s/step - accuracy: 0.8234 - loss: 0.4612 - val_accuracy: 0.7917 - val_loss: 0.7021 - learning_rate: 0.0010\n","Epoch 10/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.8774 - loss: 0.3210 - val_accuracy: 0.7738 - val_loss: 0.7276 - learning_rate: 0.0010\n","Epoch 11/20\n","\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.8840 - loss: 0.3464 - val_accuracy: 0.7857 - val_loss: 0.7158 - learning_rate: 0.0010\n","Epoch 12/20\n"]}],"source":["# Train the model with training and validation data\n","history = model.fit(\n","    train_generator,\n","    epochs=20,                           # Set the maximum number of epochs\n","    validation_data=validation_generator,  # Use validation data\n","    callbacks=[early_stopping, reduce_lr]  # Apply callbacks during training\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OayD-tLtUIzD"},"outputs":[],"source":["# Evaluate the model on the validation dataset\n","evaluation = model.evaluate(validation_generator)\n","print(f\"Akurasi Validasi: {evaluation[1] * 100:.2f}%\")  # Print validation accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdiOG9rTUKpl"},"outputs":[],"source":["# Save the trained model\n","model.save('/content/drive/Shareddrives/capstone/capstone_ml/ML-Report/')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vDVP-tjwdgze"},"outputs":[],"source":["# Import libraries for evaluation\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OjWMBCP0UMJ_"},"outputs":[],"source":["# Predict the validation data\n","Y_pred = model.predict(validation_generator)\n","y_pred = np.argmax(Y_pred, axis=1)  # Convert probabilities to class indices\n","\n","# Get true labels for validation data\n","Y_true = validation_generator.classes\n","\n","# Generate and display confusion matrix\n","cm = confusion_matrix(Y_true, y_pred)\n","print(\"Confusion Matrix:\")\n","print(cm)\n","\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n","            xticklabels=validation_generator.class_indices.keys(),\n","            yticklabels=validation_generator.class_indices.keys())\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted Labels\")\n","plt.ylabel(\"True Labels\")\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f7OVXE4ndDSa"},"outputs":[],"source":["\n","# Display classification report\n","print(\"\\nClassification Report:\")\n","print(classification_report(Y_true, y_pred, target_names=list(validation_generator.class_indices.keys())))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9DSvMRVwdGfH"},"outputs":[],"source":["# Load and predict on a single image\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","model = load_model('/content/drive/Shareddrives/capstone/capstone_ml/CC/model5/model.h5')  # Load saved model\n","\n","img_path = '/content/drive/Shareddrives/capstone/capstone_ml/MODEL/LDPE_0007.jpg'\n","img = image.load_img(img_path, target_size=(img_width, img_height))  # Load and resize image\n","img_array = image.img_to_array(img) / 255.0  # Normalize image array\n","img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","\n","predictions = model.predict(img_array)  # Predict image class probabilities\n"]},{"cell_type":"code","source":["# Print class probabilities\n","for i, prob in enumerate(predictions[0]):\n","    print(f\"Class {i}: {prob*100:.2f}%\")\n"],"metadata":{"id":"Uq456LZwZTGA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U74XgmIjdUpp"},"source":[]},{"cell_type":"code","source":["# Save training history to a file\n","import pickle\n"],"metadata":{"id":"trIq9yhYZV_a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history_path = '/content/drive/Shareddrives/capstone/capstone_ml/CC/model5/history.pkl'\n","with open(history_path, 'wb') as f:\n","    pickle.dump(history.history, f)  # Save history object\n","print(f\"History has been saved at {history_path}\")\n"],"metadata":{"id":"ZFEVCtuzZZED"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load and visualize training history\n","import pickle\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","history_path = '/content/drive/Shareddrives/capstone/capstone_ml/CC/model5/history.pkl'\n","with open(history_path, 'rb') as f:\n","    history = pickle.load(f)  # Load history object\n","\n","# Set visualization style\n","sns.set(style=\"whitegrid\")\n","fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n","\n","# Plot accuracy over epochs\n","ax[0].plot(history['accuracy'], label='Train Accuracy', marker='o', color='blue')\n","ax[0].plot(history['val_accuracy'], label='Validation Accuracy', marker='o', color='orange')\n","ax[0].set_title('Model Accuracy')\n","ax[0].set_xlabel('Epoch')\n","ax[0].set_ylabel('Accuracy')\n","ax[0].legend()\n","\n","# Plot loss over epochs\n","ax[1].plot(history['loss'], label='Train Loss', marker='o', color='blue')\n","ax[1].plot(history['val_loss'], label='Validation Loss', marker='o', color='orange')\n","ax[1].set_title('Model Loss')\n","ax[1].set_xlabel('Epoch')\n","ax[1].set_ylabel('Loss')\n","ax[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"cRCl9zvsZb40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import csv\n","\n","# Data untuk file CSV\n","data = [\n","    {\"in\": \"Input1\", \"out\": \"Output1\"},\n","    {\"in\": \"Input2\", \"out\": \"Output2\"},\n","    {\"in\": \"Input3\", \"out\": \"Output3\"},\n","    {\"in\": \"Input4\", \"out\": \"Output4\"}\n","]\n","\n","# Nama file CSV\n","file_name = \"in_out.csv\"\n","\n","# Membuat file CSV dan menuliskan data\n","with open(file_name, mode='w', newline='', encoding='utf-8') as file:\n","    # Menentukan kolom\n","    fieldnames = ['in', 'out']\n","    writer = csv.DictWriter(file, fieldnames=fieldnames)\n","\n","    # Menulis header\n","    writer.writeheader()\n","\n","    # Menulis data\n","    for row in data:\n","        writer.writerow(row)\n","\n","print(f\"File '{file_name}' berhasil dibuat dengan data in dan out!\")\n"],"metadata":{"id":"tZ5dEjPPau5F"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}